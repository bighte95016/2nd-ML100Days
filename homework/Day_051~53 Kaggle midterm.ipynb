{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import log_loss, roc_auc_score, auc, roc_curve\n",
    "\n",
    "data_root = \"../data/ML100midterm/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1160742, 7)\n",
      "(306313, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160319.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1832624</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160429.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2029232</td>\n",
       "      <td>3381</td>\n",
       "      <td>11951.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2223968</td>\n",
       "      <td>3381</td>\n",
       "      <td>9776.0</td>\n",
       "      <td>10:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>73611</td>\n",
       "      <td>2099</td>\n",
       "      <td>12034.0</td>\n",
       "      <td>100:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160207.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>163606</td>\n",
       "      <td>1569</td>\n",
       "      <td>5054.0</td>\n",
       "      <td>200:30</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20160421.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3273056</td>\n",
       "      <td>4833</td>\n",
       "      <td>7802.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20160130.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94107</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160412.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>253750</td>\n",
       "      <td>8390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>253750</td>\n",
       "      <td>8390</td>\n",
       "      <td>7531.0</td>\n",
       "      <td>20:5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160327.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>376492</td>\n",
       "      <td>1041</td>\n",
       "      <td>13490.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160127.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1964720</td>\n",
       "      <td>7884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1964720</td>\n",
       "      <td>7884</td>\n",
       "      <td>6704.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20160215.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1113008</td>\n",
       "      <td>1041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1113008</td>\n",
       "      <td>1041</td>\n",
       "      <td>11197.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160114.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2881376</td>\n",
       "      <td>5341</td>\n",
       "      <td>111.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160207.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2881376</td>\n",
       "      <td>8390</td>\n",
       "      <td>7531.0</td>\n",
       "      <td>20:5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160321.0</td>\n",
       "      <td>20160329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2881376</td>\n",
       "      <td>5341</td>\n",
       "      <td>111.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160207.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "0   1439408         2632        NaN           NaN       0.0            NaN   \n",
       "1   1439408         2632     8591.0          20:1       0.0     20160217.0   \n",
       "2   1439408         2632     1078.0          20:1       0.0     20160319.0   \n",
       "3   1832624         3381     7610.0        200:20       0.0     20160429.0   \n",
       "4   2029232         3381    11951.0        200:20       1.0     20160129.0   \n",
       "5   2223968         3381     9776.0          10:5       2.0     20160129.0   \n",
       "6     73611         2099    12034.0        100:10       NaN     20160207.0   \n",
       "7    163606         1569     5054.0        200:30      10.0     20160421.0   \n",
       "8   3273056         4833     7802.0        200:20      10.0     20160130.0   \n",
       "9     94107         3381     7610.0        200:20       2.0     20160412.0   \n",
       "10   253750         8390        NaN           NaN       0.0            NaN   \n",
       "11   253750         8390     7531.0          20:5       0.0     20160327.0   \n",
       "12   376492         1041    13490.0          30:5       2.0     20160127.0   \n",
       "13  1964720         7884        NaN           NaN      10.0            NaN   \n",
       "14  1964720         7884     6704.0          20:1      10.0     20160215.0   \n",
       "15  1113008         1041        NaN           NaN       2.0            NaN   \n",
       "16  1113008         1041    11197.0          30:5       2.0     20160114.0   \n",
       "17  2881376         5341      111.0          30:5       1.0     20160207.0   \n",
       "18  2881376         8390     7531.0          20:5       0.0     20160321.0   \n",
       "19  2881376         5341      111.0          30:5       1.0     20160207.0   \n",
       "\n",
       "          Date  \n",
       "0   20160217.0  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "5          NaN  \n",
       "6          NaN  \n",
       "7          NaN  \n",
       "8          NaN  \n",
       "9          NaN  \n",
       "10  20160327.0  \n",
       "11         NaN  \n",
       "12         NaN  \n",
       "13  20160115.0  \n",
       "14         NaN  \n",
       "15  20160114.0  \n",
       "16         NaN  \n",
       "17         NaN  \n",
       "18  20160329.0  \n",
       "19         NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#讀取train & test資料\n",
    "dfoff = pd.read_csv(os.path.join(data_root, \"train_offline.csv\"))\n",
    "dftest = pd.read_csv(os.path.join(data_root, \"test_offline.csv\"))\n",
    "\n",
    "#刪減資料並重新排列\n",
    "dftest = dftest[~dftest.Coupon_id.isna()]\n",
    "print(dfoff.shape)\n",
    "print(dftest.shape)\n",
    "dfoff.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    710665\n",
       "-1    413773\n",
       " 1     36304\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#建立label（0,1），並將train的資料定義label，作為最後判定是否使用消費卷的指標（預測結果）\n",
    "\"\"\"\"\"\n",
    "1) buy with coupon within (include) 15 days ==> 1\n",
    "2) buy with coupon but out of 15 days ==> 0\n",
    "3) buy without coupon ==> -1 (we don't care)\n",
    "\"\"\"\"\"\n",
    "\n",
    "def label(row):\n",
    "    if np.isnan(row[\"Date_received\"]):\n",
    "        return -1\n",
    "    if not np.isnan(row[\"Date\"]):\n",
    "        td = pd.to_datetime(row[\"Date\"], format=\"%Y%m%d\") - pd.to_datetime(row[\"Date_received\"], format=\"%Y%m%d\")\n",
    "        if td <= pd.Timedelta(15, \"D\"):\n",
    "            return 1\n",
    "    return 0    \n",
    "\n",
    "dfoff[\"label\"] = dfoff.apply(label, axis=1)\n",
    "dfoff[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立特徵weekday(星期幾)\n",
    "def getWeekday(row):\n",
    "    if (np.isnan(row)) or (row==-1):\n",
    "        return row\n",
    "    else :\n",
    "        return pd.to_datetime(row, format=\"%Y%m%d\").dayofweek+1\n",
    "\n",
    "dfoff[\"weekday\"] = dfoff[\"Date_received\"].apply(getWeekday)\n",
    "dftest[\"weekday\"] = dftest[\"Date_received\"].apply(getWeekday)\n",
    "\n",
    "\n",
    "#建立特徵weekday_type(是否為週末1,0)\n",
    "dfoff[\"weekday_type\"] = dfoff[\"weekday\"].astype(\"str\").apply(lambda x: 1 if x in[6,7] else 0)\n",
    "dftest[\"weekday_type\"] = dftest[\"weekday\"].astype(\"str\").apply(lambda x: 1 if x in[6,7] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'weekday_7']\n"
     ]
    }
   ],
   "source": [
    "#建立特徵weekday_cols，標籤編碼並建立pandas表格=>建立column=>將pandas值與column match(星期一～日皆是獨立特徵)\n",
    "weekdaycols = [\"weekday_\" + str(i) for i in range(1,8)]\n",
    "print(weekdaycols)\n",
    "\n",
    "tmpdf = pd.get_dummies(dfoff[\"weekday\"].replace(-1, np.nan))\n",
    "tmpdf.columns = weekdaycols\n",
    "dfoff[weekdaycols] = tmpdf\n",
    "\n",
    "tmpdf = pd.get_dummies(dftest[\"weekday\"].replace(-1, np.nan))\n",
    "tmpdf.columns = weekdaycols\n",
    "dftest[weekdaycols] = tmpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立特徵getDiscountType、convertRate、getDiscountMan、getDiscountJian （利用Discount_rate、Distance轉換）\n",
    "def getDiscountType(row):\n",
    "    if row == \"null\":\n",
    "        return \"null\"\n",
    "    elif \":\" in row:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def convertRate(row):\n",
    "    if row == \"null\":\n",
    "        return 1.0\n",
    "    elif \":\" in row:\n",
    "        rows = row.split(\":\")\n",
    "        return 1.0 - float(rows[1]) / float(rows[0])\n",
    "    else:\n",
    "        return float(row)\n",
    "    \n",
    "\n",
    "def getDiscountMan(row):\n",
    "    if \":\" in row:\n",
    "        rows = row.split(\":\")\n",
    "        return int(rows[0])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def getDiscountJian(row):\n",
    "    if \":\" in row:\n",
    "        rows = row.split(\":\")\n",
    "        return int(rows[1])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def processData(df):\n",
    "    df[\"discount_type\"] = df[\"Discount_rate\"].astype(\"str\").apply(getDiscountType)\n",
    "    df[\"discount_rate\"] = df[\"Discount_rate\"].astype(\"str\").apply(convertRate)\n",
    "    df[\"discount_man\"] = df[\"Discount_rate\"].astype(\"str\").apply(getDiscountMan)\n",
    "    df[\"discount_jian\"] = df[\"Discount_rate\"].astype(\"str\").apply(getDiscountJian)\n",
    "    \n",
    "    df.loc[df.Distance.isna(), \"Distance\"] = 99\n",
    "    return df\n",
    "    \n",
    "\n",
    "dfoff = processData(dfoff)\n",
    "dftest = processData(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size:667753, #positive:32472\n",
      "valid size:79216, #positive:3832\n"
     ]
    }
   ],
   "source": [
    "#將訓練資料(train data)分成兩組train & valid\n",
    "def split_train_valid(row, date_cut = \"20160416\"):\n",
    "    is_train = True if pd.to_datetime(row, format=\"%Y%m%d\") < pd.to_datetime(date_cut, format=\"%Y%m%d\") else False\n",
    "    return is_train\n",
    "\n",
    "df = dfoff[dfoff[\"label\"]!=-1].copy()\n",
    "df[\"is_train\"] = df[\"Date_received\"].apply(split_train_valid)\n",
    "\n",
    "train = df[df[\"is_train\"]]\n",
    "valid = df[~df[\"is_train\"]]\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "valid.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"train size:{}, #positive:{}\".format(len(train), train[\"label\"].sum()))\n",
    "print(\"valid size:{}, #positive:{}\".format(len(valid), valid[\"label\"].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 ['discount_type', 'discount_rate', 'discount_man', 'discount_jian', 'Distance', 'weekday', 'weekday_type', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'weekday_7']\n"
     ]
    }
   ],
   "source": [
    "#列出主要訓練資料使用的特徵值\n",
    "original_feature = [\"discount_type\", \"discount_rate\", \"discount_man\", \"discount_jian\", \"Distance\", \"weekday\", \"weekday_type\"] + weekdaycols\n",
    "print(len(original_feature), original_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['discount_type', 'discount_rate', 'discount_man', 'discount_jian', 'Distance', 'weekday', 'weekday_type', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'weekday_7']\n"
     ]
    }
   ],
   "source": [
    "#建立model，先利用StandardScaler() ＆ classifier()，並利用GridSearchCV取得最佳參數\n",
    "predictors = original_feature\n",
    "print(predictors)\n",
    "\n",
    "def check_model(data, predictors):\n",
    "    classifier = lambda: SGDClassifier(loss=\"log\", penalty=\"elasticnet\", shuffle=True, fit_intercept=True, max_iter=100, n_jobs=1, class_weight=None)\n",
    "    \n",
    "    model = Pipeline(steps=[(\"ss\", StandardScaler()), (\"en\", classifier())])\n",
    "    \n",
    "    parameters = {\"en__alpha\":[0.001, 0.01, 0.1], \"en__l1_ratio\":[0.001, 0.01, 0.1]}\n",
    "                    \n",
    "    folder = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "                     \n",
    "    \n",
    "    grid_search = GridSearchCV(model, parameters, cv=folder, n_jobs=-1, verbose=1)\n",
    "    grid_search = grid_search.fit(data[predictors], data[\"label\"])\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  1.9min finished\n",
      "/Users/daihongming/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/daihongming/anaconda3/lib/python3.7/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/Users/daihongming/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#將train data帶入model去fit\n",
    "model = check_model(train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daihongming/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py:381: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "#用valid data去預測結果，predict_proba結果為兩行(一行為預測標籤為0的機率，一行為預測標籤為1的機率)\n",
    "y_valid_pred = model.predict_proba(valid[predictors])\n",
    "valid1 = valid.copy()\n",
    "valid1[\"valid_prob\"] = y_valid_pred[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00686939, 0.00601692, 0.00926648, ..., 0.00807127, 0.00681002,\n",
       "       0.00546361])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid_pred[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.743, Accuracy: 0.952\n"
     ]
    }
   ],
   "source": [
    "#計算valid data預測準度(利用auc_roc_score, accuracy_socre)\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "auc_score = roc_auc_score(y_true=valid.label, y_score=y_valid_pred[:, 1] )\n",
    "acc = accuracy_score(y_true=valid.label, y_pred = y_valid_pred.argmax(axis=1))\n",
    "print(\"Validation AUC: {:.3f}, Accuracy: {:.3f}\".format(auc_score, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['User_id', 'Merchant_id', 'Coupon_id', 'Discount_rate', 'Distance',\n",
       "       'Date_received', 'weekday', 'weekday_type', 'weekday_1', 'weekday_2',\n",
       "       'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'weekday_7',\n",
       "       'discount_type', 'discount_rate', 'discount_man', 'discount_jian'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#測試集最後的columns\n",
    "dftest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306313, 19)\n",
      "(306313, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daihongming/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py:381: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "#去除test data內Coupon_id為0的資料\n",
    "targetset = dftest.copy()\n",
    "print(targetset.shape)\n",
    "\n",
    "targetset = targetset[~targetset.Coupon_id.isna()]\n",
    "targetset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#選出用來預測的特徵值資料(predictors)\n",
    "testset = targetset[predictors].copy()\n",
    "\n",
    "#預測test data的結果\n",
    "y_test_pred = model.predict_proba(testset[predictors])\n",
    "test1 = testset.copy()\n",
    "test1[\"pred_prob\"] = y_test_pred[:, 1]\n",
    "print(test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>pred_prob</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>11002</td>\n",
       "      <td>20160528</td>\n",
       "      <td>0.013494</td>\n",
       "      <td>1439408_11002_20160528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>8591</td>\n",
       "      <td>20160613</td>\n",
       "      <td>0.065329</td>\n",
       "      <td>1439408_8591_20160613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>8591</td>\n",
       "      <td>20160516</td>\n",
       "      <td>0.065329</td>\n",
       "      <td>1439408_8591_20160516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2029232</td>\n",
       "      <td>1532</td>\n",
       "      <td>20160530</td>\n",
       "      <td>0.060906</td>\n",
       "      <td>2029232_1532_20160530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2029232</td>\n",
       "      <td>12737</td>\n",
       "      <td>20160519</td>\n",
       "      <td>0.098407</td>\n",
       "      <td>2029232_12737_20160519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id Coupon_id Date_received  pred_prob                     uid\n",
       "0  1439408     11002      20160528   0.013494  1439408_11002_20160528\n",
       "1  1439408      8591      20160613   0.065329   1439408_8591_20160613\n",
       "2  1439408      8591      20160516   0.065329   1439408_8591_20160516\n",
       "3  2029232      1532      20160530   0.060906   2029232_1532_20160530\n",
       "4  2029232     12737      20160519   0.098407  2029232_12737_20160519"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#將三種id取出，並加入預測結果併成一datafram\n",
    "output = pd.concat((targetset[[\"User_id\", \"Coupon_id\", \"Date_received\"]], test1[\"pred_prob\"]), axis=1)\n",
    "\n",
    "output.loc[:, \"User_id\"] = output[\"User_id\"].apply(lambda x: str(int(x)))\n",
    "output.loc[:, \"Coupon_id\"] = output[\"Coupon_id\"].apply(lambda x: str(int(x)))\n",
    "output.loc[:, \"Date_received\"] = output[\"Date_received\"].apply(lambda x: str(int(x)))\n",
    "\n",
    "#將三種id整合為一column\n",
    "output[\"uid\"] = output[[\"User_id\", \"Coupon_id\", \"Date_received\"]].apply(lambda x: \"_\".join(x.values), axis=1)\n",
    "\n",
    "output.reset_index(drop=True, inplace=True)\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000020_2705_20160519</td>\n",
       "      <td>0.114257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000020_8192_20160513</td>\n",
       "      <td>0.088141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000065_1455_20160527</td>\n",
       "      <td>0.067587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000085_8067_20160513</td>\n",
       "      <td>0.070539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000086_2418_20160613</td>\n",
       "      <td>0.060906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     uid     label\n",
       "0  1000020_2705_20160519  0.114257\n",
       "1  1000020_8192_20160513  0.088141\n",
       "2  1000065_1455_20160527  0.067587\n",
       "3  1000085_8067_20160513  0.070539\n",
       "4  1000086_2418_20160613  0.060906"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#將預測結果轉換為csv檔\n",
    "out = output.groupby(\"uid\", as_index=False).mean()\n",
    "out[[\"uid\", \"pred_prob\" ]]\n",
    "out.columns = [\"uid\", \"label\"]\n",
    "\n",
    "out.to_csv(\"2nd_ML_midterm.csv\", header=[\"uid\", \"label\"], index=False)\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
